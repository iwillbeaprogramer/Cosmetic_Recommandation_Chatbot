{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  nltk\n",
    "from nltk import load_parser\n",
    "nltk.data.show_cfg('grammars/book_grammars/sql0.fcfg')\n",
    "cp = load_parser('grammars/book_grammars/sql0.fcfg')\n",
    "query = 'What cities are located in China'\n",
    "for tree in cp.parse(query.split()):\n",
    "    print(\"--> tree[{}]\".format(tree))\n",
    "trees = next(cp.parse(query.split()))\n",
    "print()\n",
    "print(\"--> type(trees)[{}]\".format(type(trees)))\n",
    "answer = trees[0].label()\n",
    "print()\n",
    "print(\"--> type(answer)[{}]\".format(type(answer)))\n",
    "aa=answer.get('SEM')\n",
    "print()\n",
    "print(\"--> {}\".format(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start USR\n",
      "# IBIS / domain-independent\n",
      "USR[sem=?s] -> ANSWER[sem=?s] | ASK[sem=?s]\n",
      "ASK[sem=[Ask=?q]] -> WHQ[q=?q]\n",
      "ANSWER[sem=[Answer=?ans]] -> SHORTANS[ans=?ans] | YESNOANS[ans=?ans]\n",
      "SHORTANS[ans=?ind] -> CAT[cat=?cat, ind=?ind]\n",
      "YESNOANS[ans=yes] -> 'yes' | 'yeah'\n",
      "YESNOANS[ans=yes] -> 'no' | 'nope'\n",
      "# travel\n",
      "WHQ[q=price] -> 'price'\n",
      "CAT[cat=how, ind=plane] -> 'plane' | 'flight'\n",
      "CAT[cat=how, ind=train] -> 'train'\n",
      "CAT[cat=city, ind=london] -> 'london'\n",
      "CAT[cat=city, ind=paris]  -> 'paris'\n",
      "CAT[cat=city, ind=berlin] -> 'berlin'\n",
      "CAT[cat=class, ind=first]  -> 'first' | 'business'\n",
      "CAT[cat=class, ind=second] -> 'second' | 'economy'\n",
      "CAT[cat=day, ind=today]    -> 'today'\n",
      "CAT[cat=day, ind=tomorrow] -> 'tomorrow'\n",
      "NON[sem=''] -> 'please' | \"What's\" | 'the' | 'give' | 'me' | 'information' | 'I' | 'want' | 'to' | 'know' | 'about' | '?' | '!'\n",
      "\n",
      "(USR[sem=[Ask='price']]\n",
      "  (ASK[sem=[Ask='price']] (WHQ[q='price'] price)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import  nltk\n",
    "from nltk import load_parser\n",
    "\n",
    "nltk.data.show_cfg('travel_test.fcfg')\n",
    "print()\n",
    "cp = load_parser('travel_test.fcfg')\n",
    "query = 'price'\n",
    "# query = 'please price information'\n",
    "for tree in cp.parse(query.split()):\n",
    "    print(tree)\n",
    "print()\n",
    "# parse_trees = cp.parse(query.split())\n",
    "# for parse_tree in parse_trees:\n",
    "#     print(\"parse_tree--> {}\".format(parse_tree))\n",
    "# trees = next(parse_trees)\n",
    "# print(\"parse_trees--> {}\".format(parse_trees))\n",
    "# answer = parse_trees[0].label().get('sem')\n",
    "# answer = parse_trees[0].label()\n",
    "# aa=answer.get('sem')\n",
    "# key0=answer.keys()\n",
    "# print(\"key--> {}\".format([key for key in key0]))\n",
    "# print(\"answer--> {}\".format(answer))\n",
    "# for key in key0:\n",
    "#     print(\"answer[key]--> {}\".format(answer[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  nltk\n",
    "from nltk import load_parser\n",
    "cp = load_parser('travel.fcfg')\n",
    "query = 'price'\n",
    "# trees = next(cp.parse(query.split()))\n",
    "# answer = trees[0].label()\n",
    "# key=\"Ask\"\n",
    "# answer[key]\n",
    "i=0\n",
    "for tree in next(cp.parse(query.split())):\n",
    "    print(i)\n",
    "    print(tree)\n",
    "    i=+1\n",
    "# print(\"--> {}\".format(type(answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=(SELECT, City FROM city_table, WHERE, , , Country=\"china\")]\n",
      "  (NP[SEM=(SELECT, City FROM city_table)]\n",
      "    (Det[SEM='SELECT'] What)\n",
      "    (N[SEM='City FROM city_table'] cities))\n",
      "  (VP[SEM=(, , Country=\"china\")]\n",
      "    (IV[SEM=''] are)\n",
      "    (AP[SEM=(, Country=\"china\")]\n",
      "      (A[SEM=''] located)\n",
      "      (PP[SEM=(, Country=\"china\")]\n",
      "        (P[SEM=''] in)\n",
      "        (NP[SEM='Country=\"china\"'] China)))))\n"
     ]
    }
   ],
   "source": [
    "import  nltk\n",
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/sql0.fcfg')\n",
    "query = 'What cities are located in China'\n",
    "for tree in cp.parse(query.split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    "\n",
    "text1 = \"price?\"\n",
    "text2 = \"price information!\"\n",
    "\n",
    "vector1 = text_to_vector(text1)\n",
    "vector2 = text_to_vector(text2)\n",
    "\n",
    "cosine = get_cosine(vector1, vector2)\n",
    "\n",
    "print(\"Cosine:{}\".format(cosine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
