{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Chatbots with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conversations, context is king! We’ll build a chatbot framework using Tensorflow and add some context handling to show how this can be approached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ever wonder why most chatbots lack conversational [context](https://chatbotsmagazine.com/maintaining-context-in-chatbots-2016b6a5b7c6)?\n",
    "\n",
    "How is this possible given the importance of context in nearly all conversations?\n",
    "\n",
    "We’re going to create a [chatbot framework](https://chatbotsmagazine.com/design-framework-for-chatbots-aa27060c4ea3) and build a conversational model for an **island moped rental shop**. The chatbot for this small business needs to handle simple questions about hours of operation, reservation options and so on. We also want it to handle contextual responses such as inquiries about same-day rentals. Getting this right [could save a vacation](https://medium.com/p/how-a-messaging-app-saved-my-vacation-192b031a96f5)!\n",
    "\n",
    "We’ll be working through 3 steps:\n",
    "\n",
    "* We’ll transform conversational intent definitions to a Tensorflow model\n",
    "* Next, we will build a chatbot framework to process responses\n",
    "* Lastly, we’ll show how basic context can be incorporated into our response processor\n",
    "\n",
    "We’ll be using **[tflearn](http://tflearn.org/)**, a layer above **[tensorflow](https://www.tensorflow.org/)**, and of course **[Python](https://www.python.org/)**. As always we’ll use **[Python notebook](https://ipython.org/notebook.html)** as a tool to facilitate our work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Conversational Intent Definitions to a Tensorflow Model\n",
    "The complete notebook for our first step is [here](https://github.com/ugik/notebooks/blob/master/Tensorflow%20chat-bot%20model.ipynb).\n",
    "\n",
    "A chatbot framework needs a structure in which conversational intents are defined. One clean way to do this is with a JSON file, like [this](https://github.com/ugik/notebooks/blob/master/intents.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chatbot intents](figs/1_pcbw_Y4acT750-lL98iw2Q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each conversational intent contains:\n",
    "\n",
    "* a **tag** (a unique name)\n",
    "* **patterns** (sentence patterns for our neural network text classifier)\n",
    "* **responses** (one will be used as a response)\n",
    "\n",
    "And later on we’ll add some basic contextual elements.\n",
    "\n",
    "First we take care of our imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# things we need for NLP\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# things we need for Tensorflow\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at \"[Deep Learning in 7 lines of code](https://chatbotslife.com/deep-learning-in-7-lines-of-code-7879a8ef8cfb)\" for a primer or [here](https://chatbotslife.com/tensorflow-demystified-80987184faf7) if you need to demystify Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our chat-bot intents file\n",
    "import json\n",
    "with open('intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our intents JSON [file](https://github.com/ugik/notebooks/blob/master/intents.json) loaded, we can now begin to organize our documents, words and classification classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 documents\n",
      "9 classes ['goodbye', 'greeting', 'hours', 'mopeds', 'opentoday', 'payments', 'rental', 'thanks', 'today']\n",
      "48 unique stemmed words [\"'d\", \"'s\", 'a', 'acceiv', 'anyon', 'ar', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'do', 'doe', 'good', 'goodby', 'hav', 'hello', 'help', 'hi', 'hour', 'how', 'i', 'is', 'kind', 'lat', 'lik', 'mastercard', 'mop', 'of', 'on', 'op', 'rent', 'see', 'tak', 'thank', 'that', 'ther', 'thi', 'to', 'today', 'we', 'what', 'when', 'which', 'work', 'yo', 'you']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# remove duplicates\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of documents (sentences), each sentence is a list of stemmed words and each document is associated with an intent (a class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stem ‘tak’ will match ‘take’, ‘taking’, ‘takers’, etc. We could clean the words list and remove useless entries but this will suffice for now.\n",
    "\n",
    "Unfortunately this data structure won’t work with Tensorflow, we need to transform it further: from documents of words into tensors of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "output = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# create train and test lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our data is shuffled. Tensorflow will take some of this and use it as test data to gauge accuracy for a newly fitted model.\n",
    "\n",
    "If we look at a single x and y list element, we see ‘[bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model)’ arrays, one for the intent pattern, the other for the intent class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**train_x example**: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
    "\n",
    "**train_y example**: [0, 0, 1, 0, 0, 0, 0, 0, 0] \n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re ready to build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.01563\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 1000 | loss: 0.01563 - acc: 1.0000 -- iter: 24/27\n",
      "Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.01559\u001b[0m\u001b[0m | time: 0.017s\n",
      "| Adam | epoch: 1000 | loss: 0.01559 - acc: 1.0000 -- iter: 27/27\n",
      "--\n",
      "INFO:tensorflow:/mnt/d/NLP_MachineLearnning/text-mining-camp/note/arkwith/Contextual_Chatbots/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "model.save('model.tflearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same tensor structure as we used in our 2-layer neural network in [our ‘toy’ example](https://chatbotslife.com/deep-learning-in-7-lines-of-code-7879a8ef8cfb). Watching the model fit our training data never gets old…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interactive build of a model in tflearn](figs/1_5UIqnedBzsYTXJ81wEU-vg.GIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this section of work, we’ll save (‘pickle’) our model and documents so the next notebook can use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all of our data structures\n",
    "import pickle\n",
    "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![...](figs/1_f9Sq7I_pauPQ9u4PbtPt4w.JPEG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Our Chatbot Framework\n",
    "\n",
    "The complete notebook for our second step is [here](https://github.com/ugik/notebooks/blob/master/Tensorflow%20chat-bot%20response.ipynb).\n",
    "\n",
    "We’ll build a simple state-machine to handle responses, using our intents model (from the previous step) as our classifier. That’s [how chatbots work](https://medium.freecodecamp.com/how-chat-bots-work-dfff656a35e2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>A contextual chatbot framework is a classifier within a state-machine.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the same imports, we’ll un-pickle our model and documents as well as reload our intents file. Remember our chatbot framework is separate from our model build — you don’t need to rebuild your model unless the intent patterns change. With several hundred intents and thousands of patterns the model could take several minutes to build.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore all of our data structures\n",
    "import pickle\n",
    "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
    "words = data['words']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "\n",
    "# import our chat-bot intents file\n",
    "import json\n",
    "with open('intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load our saved Tensorflow (tflearn framework) model. Notice you first need to define the Tensorflow model structure just as we did in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /mnt/d/NLP_MachineLearnning/text-mining-camp/note/arkwith/Contextual_Chatbots/model.tflearn\n"
     ]
    }
   ],
   "source": [
    "# load our saved model\n",
    "model.load('./model.tflearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can begin processing intents, we need a way to produce a bag-of-words from user input. This is the same technique as we used earlier to create our training documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "p = bow(\"is your shop open today?\", words)\n",
    "print (p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to build our response processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_THRESHOLD = 0.25\n",
    "def classify(sentence):\n",
    "    # generate probabilities from the model\n",
    "    results = model.predict([bow(sentence, words)])[0]\n",
    "    # filter out predictions below a threshold\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1]))\n",
    "    # return tuple of intent and probability\n",
    "    return return_list\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    # if we have a classification then find the matching intent tag\n",
    "    if results:\n",
    "        # loop as long as there are matches to process\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    # a random response from the intent\n",
    "                    return print(random.choice(i['responses']))\n",
    "\n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sentence passed to response() is classified. Our classifier uses model.predict() and is lighting fast. The probabilities returned by the model are lined-up with our intents definitions to produce a list of potential responses.\n",
    "\n",
    "If one or more classifications are above a threshold, we see if a tag matches an intent and then process that. We’ll treat our classification list as a stack and pop off the stack looking for a suitable match until we find one, or it’s empty.\n",
    "\n",
    "Let’s look at a classification example, the most likely tag and its probability are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opentoday', 0.9417437)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('is your shop open today?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that ‘is your shop open today?’ is not one of the patterns for this intent: “patterns”: [“Are you open today?”, “When do you open today?”, “What are your hours today?”] however the terms ‘open’ and ‘today’ proved irresistible to our model (they are prominent in the chosen intent).\n",
    "\n",
    "We can now generate a chatbot response from user-input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're open every day from 9am-9pm\n"
     ]
    }
   ],
   "source": [
    "response('is your shop open today?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And other context-free responses…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We accept VISA, Mastercard and AMEX\n"
     ]
    }
   ],
   "source": [
    "response('do you take cash?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We rent Yamaha, Piaggio and Vespa mopeds\n"
     ]
    }
   ],
   "source": [
    "response('what kind of mopeds do you rent?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have a nice day\n"
     ]
    }
   ],
   "source": [
    "response('Goodbye, see you later')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![...](figs/1_RrQH1Mt6R73nq6lO6vTZ2w.JPEG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s work in some basic context into our moped rental chatbot conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualization\n",
    "\n",
    "We want to handle a question about renting a moped and ask if the rental is for today. That clarification question is a simple contextual response. If the user responds ‘today’ and the context is the rental timeframe then it’s best they call the rental company’s 1–800 #. No time to waste.\n",
    "\n",
    "To achieve this we will add the notion of ‘state’ to our framework. This is comprised of a data-structure to maintain state and specific code to manipulate it while processing intents.\n",
    "\n",
    "Because the state of our state-machine needs to be easily persisted, restored, copied, etc. it’s important to keep it all in a data structure such as a dictionary.\n",
    "\n",
    "Here’s our response process with basic contextualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data structure to hold user context\n",
    "context = {}\n",
    "\n",
    "ERROR_THRESHOLD = 0.25\n",
    "def classify(sentence):\n",
    "    # generate probabilities from the model\n",
    "    results = model.predict([bow(sentence, words)])[0]\n",
    "    # filter out predictions below a threshold\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1]))\n",
    "    # return tuple of intent and probability\n",
    "    return return_list\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    # if we have a classification then find the matching intent tag\n",
    "    if results:\n",
    "        # loop as long as there are matches to process\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    # set context for this intent if necessary\n",
    "                    if 'context_set' in i:\n",
    "                        if show_details: print ('context:', i['context_set'])\n",
    "                        context[userID] = i['context_set']\n",
    "\n",
    "                    # check if this intent is contextual and applies to this user's conversation\n",
    "                    if not 'context_filter' in i or \\\n",
    "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
    "                        if show_details: print ('tag:', i['tag'])\n",
    "                        # a random response from the intent\n",
    "                        return print(random.choice(i['responses']))\n",
    "\n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our context state is a dictionary, it will contain state for each user. We’ll use some unique identified for each user (eg. cell #). This allows our framework and state-machine to maintain state for multiple users simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # #create a data structure to hold user context\n",
    "\n",
    "> ### context = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context handlers are added within the intent processing flow, shown again below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-22-6ff0e22d1b69>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-6ff0e22d1b69>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    return print(random.choice(i['responses']))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "                if i['tag'] == results[0][0]:\n",
    "                    # set context for this intent if necessary\n",
    "                    if 'context_set' in i:\n",
    "                        if show_details: print ('context:', i['context_set'])\n",
    "                        context[userID] = i['context_set']\n",
    "\n",
    "                    # check if this intent is contextual and applies to this user's conversation\n",
    "                    if not 'context_filter' in i or \\\n",
    "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
    "                        if show_details: print ('tag:', i['tag'])\n",
    "                        # a random response from the intent\n",
    "                        return print(random.choice(i['responses']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an intent wants to set context, it can do so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> {“tag”: “rental”,\n",
    "\n",
    "> “patterns”: [“Can we rent a moped?”, “I’d like to rent a moped”, … ],\n",
    "\n",
    "> “responses”: [“Are you looking to rent today or later this week?”],\n",
    "\n",
    "> **“context_set”: “rentalday”**\n",
    "\n",
    "> }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If another intent wants to be contextually linked to a context, it can do that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">{“tag”: “today”,\n",
    "\n",
    "> “patterns”: [“today”],\n",
    "\n",
    "> “responses”: [“For rentals today please call 1–800-MYMOPED”, …],\n",
    "\n",
    ">**“context_filter”: “rentalday”**\n",
    "\n",
    "> }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, if a user just typed ‘today’ out of the blue (no context), our ‘today’ intent won’t be processed. If they enter ‘today’ as a response to our clarification question (intent tag:‘rental’) then the intent is processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**response**('we want to rent a moped')\n",
    "\n",
    ">Are you looking to rent today or later this week?\n",
    "\n",
    "\n",
    ">**response**('today')\n",
    "\n",
    ">Same-day rentals please call 1-800-MYMOPED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our context state changed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**context**\n",
    "\n",
    ">{'123': 'rentalday'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined our ‘greeting’ intent to clear context, as is often the case with small-talk. We add a ‘show_details’ parameter to help us see inside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">**response**(\"Hi there!\", show_details=True)\n",
    "\n",
    ">context: ' '\n",
    "\n",
    ">tag: greeting\n",
    "\n",
    ">Good to see you again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try the ‘today’ input once again, a few notable things here…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">**response**('today')\n",
    "\n",
    ">We're open every day from 9am-9pm\n",
    "\n",
    "\n",
    ">**classify**('today')\n",
    "\n",
    ">[('today', 0.5322513580322266), ('opentoday', 0.2611265480518341)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, our response to the context-free ‘today’ was different. Our classification produced 2 suitable intents, and the ‘opentoday’ was selected because the ‘today’ intent, while higher probability, was bound to a context that no longer applied. Context matters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">**response**(\"thanks, your great\")\n",
    "\n",
    ">Happy to help!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![...](figs/1_YsxOYwba2fii9G98UXp1pw.JPEG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to consider now that contextualization is happening…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With State Comes Statefulness\n",
    "That’s right, your chatbot will no longer be happy as a stateless service.\n",
    "\n",
    "Unless you want to reconstitute state, reload your model and documents — with every call to your chatbot framework, you’ll need to make it stateful.\n",
    "\n",
    "This isn’t that difficult. You can run a stateful chatbot framework in its own process and call it using an RPC (remote procedure call) or RMI (remote method invocation), I recommend [Pyro](http://pythonhosted.org/Pyro4/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RMI client and server setup](figs/1_hpbuSvovqSyVY-nhBcoIaQ.JPEG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user-interface (client) is typically stateless, eg. HTTP or SMS.\n",
    "\n",
    "Your chatbot client will make a Pyro function call, which your stateful service will handle. Voila!\n",
    "\n",
    "[Here](https://chatbotslife.com/build-a-working-sms-chat-bot-in-10-minutes-b8278d80cc7a)’s a step-by-step guide to build a Twilio SMS chatbot client, and [here](https://chatbotnewsdaily.com/build-a-facebook-messenger-chat-bot-in-10-minutes-5f28fe0312cd)’s one for FB Messenger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thou Shalt Not Store State in Local Variables\n",
    "All state information must be placed in a data structure such as a dictionary, easily persisted, reloaded, or copied atomically.\n",
    "\n",
    "Each user’s conversation will carry context which will be carried statefully for that user. The user ID can be their cell #, a Facebook user ID, or some other unique identifier.\n",
    "\n",
    "There are scenarios where a user’s conversational state needs to be copied (by value) and then restored as a result of intent processing. If your state machine carries state across variables within your framework you will have a difficult time making this work in real life scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center>\n",
    "## *Python dictionaries are your friend.*\n",
    "    ...\n",
    "<center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you have a chatbot framework, a recipe for making it a stateful service, and a starting-point for adding context. Most chatbot frameworks in the future will treat context seamlessly.\n",
    "\n",
    "Think of creative ways for intents to impact and react to different context settings. Your users’ context dictionary can contain a wide-variety of conversation context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
