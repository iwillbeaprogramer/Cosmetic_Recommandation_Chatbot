{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로 추상화와 간소화, TFLearn\n",
    "\n",
    "> TFLearn은 텐서플로의 추상화 라이브러리이다. 이번에는 **TFLearn** 에 대해 알아보도록 하자.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFLearn 설치\n",
    "\n",
    "[TFLearn](http://tflearn.org/)은 텐서플로에 포함되어 있지 않기 때문에 별도의 설치가 필요하다. Terminal(또는 cmd창)에 pip 명령을 이용해 설치할 수 있다.\n",
    "\n",
    "```\n",
    "pip install tflearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "TFLearn은 Chap07.1 - tf.estimator와 유사하지만, TFLearn을 사용하면 조금 더 깔끔하게 모델을 만들 수 있다. TFLearn.org에서는 TFLearn을 다음과 같이 소개하고 있다.\n",
    "\n",
    "> Easy-to-use and understand high-level API for implementing deep neural networks, with tutorial and examples.\n",
    "\n",
    "> Fast prototyping through highly modular built-in neural network layers, regularizers, optimizers, metrics...\n",
    "\n",
    "> Full transparency over Tensorflow. All functions are built over tensors and can be used independently of TFLearn.\n",
    "\n",
    "> Powerful helper functions to train any TensorFlow graph, with support of multiple inputs, outputs and optimizers.\n",
    "\n",
    "> Easy and beautiful graph visualization, with details about weights, gradients, activations and more...\n",
    "\n",
    "> Effortless device placement for using multiple CPU/GPU.\n",
    "\n",
    " \n",
    "\n",
    "TFLearn에서의 모델 생성은 ```regression()```을 사용하여 래핑되고 마무리된다. ```regression()```함수에서 손실함수(loss) 및 최적화(optimizer)를 설정해준다.\n",
    "\n",
    "그렇다면, TFLearn을 이용해 MNIST 데이터를 분류하는 CNN 모델을 만들어 보도록 하자.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tflearn\n",
    "import tflearn.datasets.mnist as mnist\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 로딩하고 기본적인 변환을 수행\n",
    "train_x, train_y, test_x, test_y = mnist.load_data(one_hot=True, \n",
    "                                                   data_dir='../data')\n",
    "train_x = train_x.reshape([-1, 28, 28, 1])\n",
    "test_x = test_x.reshape([-1, 28, 28, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of original training examples:\", len(train_x))\n",
    "print(\"Number of original test examples:\", len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(train_y[0])\n",
    "\n",
    "plt.imshow(train_x[0, :, :, 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the network\n",
    "CNN = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "CNN = conv_2d(CNN, 32, 5, activation='relu', regularizer=\"L2\")\n",
    "CNN = max_pool_2d(CNN, 2)\n",
    "CNN = local_response_normalization(CNN)\n",
    "CNN = conv_2d(CNN, 64, 5, activation='relu', regularizer='L2')\n",
    "CNN = max_pool_2d(CNN, 2)\n",
    "CNN = local_response_normalization(CNN)\n",
    "CNN = fully_connected(CNN, 1024, activation=None)\n",
    "CNN = dropout(CNN, 0.5)\n",
    "CNN = fully_connected(CNN, 10, activation='softmax')\n",
    "CNN = regression(CNN, optimizer='adam', learning_rate=0.0001, \n",
    "                 loss='categorical_crossentropy', name='target')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the network\n",
    "model = tflearn.DNN(CNN, tensorboard_verbose=0, \n",
    "                    tensorboard_dir='./MNIST_tflearn_board/', \n",
    "                    checkpoint_path='./MNIST_tflearn_checkpoints/checkpoint')\n",
    "model.fit({'input': train_x}, {'target': train_y}, n_epoch=3,\n",
    "          validation_set=({'input': test_x}, {'target': test_y}),\n",
    "          snapshot_step=1000, show_metric=True, run_id='convnet_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 `tflearn.DNN()`함수는 `tf.estimator.Estimator()`와 비슷한 기능을 하는데, `regression()`으로 래핑된 모델을 인스턴스화하고 만들어진 모델을 전달하는 역할을 한다. 또한 텐서보드(TensorBoard)와 체크포인트(checkpoint) 디렉터리 등을 설정할 수 있다. 모델 적합 연산은 `.fit()` 메서드를 이용해 수행된다. \n",
    "\n",
    "모델 적합(`.fit()`), 즉 학습이 완료되면, 다음과 같은 메소드를 이용해 모델을 평가, 예측, 저장 및 불러오기 등을 수행할 수 있다.\n",
    "\n",
    "| 메서드\t| 설명|\n",
    "|:---|:---|\n",
    "| `evaluate(X, Y, batch_size)` | 주어진 샘플에서 모델을 평가|\n",
    "| `fit(X, Y, n_epoch)` | 입력 feature X와 타겟 Y를 모델에 적용하여 학습|\n",
    "| `get_weights(weight_tensor)` | 변수의 가중치를 반환|\n",
    "| `load(model_file)` | 학습된 모델 가중치를 불러오기|\n",
    "| `predict(x)` | 주어진 x 데이터를 모델을 이용해 예측|\n",
    "| `save(model_file)` | 학습된 모델 가중치를 저장|\n",
    "| `set_weights(tensor, weights)` | 주어진 값을 텐서 변수에 할당|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the network\n",
    "evaluation = model.evaluate(X=test_x, Y=test_y, batch_size=128)\n",
    "print(evaluation)\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(test_x)\n",
    "accuarcy = (np.argmax(pred, 1)==np.argmax(test_y, 1)).mean()\n",
    "print(accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "\n",
    "이번에는 TFLearn을 이용해 RNN을 구현해 보도록하자. 구현할 RNN 모델은 영화 리뷰에 대한 감성분석으로, 리뷰에 대해 좋거나/나쁘거나 두 개의 클래스를 분류하는 모델이다. 데이터는 학습 및 테스트 데이터가 각각 25,000개로 이루어진 [IMDb](https://www.imdb.com/interfaces/) 리뷰 데이터를 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMDb 데이터셋 로드\n",
    "(train_x, train_y), (test_x, test_y), _ = imdb.load_data(path='../data/imdb.pkl', \n",
    "                                                         n_words=10000,\n",
    "                                                         valid_portion=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 22500\n",
      "테스트용 리뷰 개수 : 2500\n",
      "카테고리 : 2\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 리뷰 개수 : {}'.format(len(train_x)))\n",
    "print('테스트용 리뷰 개수 : {}'.format(len(test_x)))\n",
    "num_classes = max(train_y) + 1\n",
    "print('카테고리 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터가 어떻게 구성되어있는지를 확인하기 위해 첫번째 훈련용 리뷰를 출력해보았습니다. 다시 말해, 22,500개의 영화 리뷰 중 첫번째 리뷰 텍스트와 그 리뷰에 대한 레이블을 출력해보는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 25, 10, 406, 26, 14, 56, 61, 62, 323, 4]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 훈련용 리뷰(X_train[0], y_train[0])에서 리뷰 본문에 해당하는 X_train[0]에는 숫자들이 들어있습니다. 이 데이터는 토큰화와 정수 인코딩이라는 텍스트 전처리가 끝난 상태입니다. IMDB 리뷰 데이터는 전체 데이터에서 각 단어들의 등장 빈도에 따라서 인덱스를 부여했습니다. 숫자가 낮을수록 이 데이터에서 등장 빈도 순위가 높습니다. 위에서 단어 집합의 크기를 제한하지 않았기 때문에 406과 같은 큰 숫자도 보입니다.\n",
    "\n",
    "첫번째 훈련용 리뷰의 레이블에 해당하는 y_train[0]의 값은 1입니다. 이 값은 첫번째 훈련 데이터가 2개의 카테고리 중 1에 해당하는 카테고리임을 의미합니다. 이 예제의 경우 감성 정보로서 0 또는 1의 값을 가지는데, 이 경우에는 부정을 의미하는 1의 값을 가집니다.\n",
    "\n",
    "22,500개의 훈련용 리뷰의 각 길이는 전부 다른데, 리뷰의 길이 분포를 그래프로 시각화해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 2820\n",
      "리뷰의 평균 길이 : 284.0717333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "len_result = [len(s) for s in train_x]\n",
    "\n",
    "print('리뷰의 최대 길이 : {}'.format(np.max(len_result)))\n",
    "print('리뷰의 평균 길이 : {}'.format(np.mean(len_result)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(len_result)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(len_result, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 레이블에 대한 빈도수:\n",
      "[[    0     1]\n",
      " [11250 11250]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_y, return_counts=True)\n",
    "print(\"각 레이블에 대한 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22,500개의 리뷰가 존재하는데 두 레이블 0과 1은 각각 11,265개로 균등한 분포를 가지고 있습니다. train_x에 들어있는 숫자들이 각각 어떤 단어들을 나타내고 있는지 확인해보겠습니다. imdb.get_word_index()에 각 단어와 맵핑되는 정수가 저장되어져 있습니다. 주의할 점은 imdb.get_word_index()에 저장된 값에 +3을 해야 실제 맵핑되는 정수입니다. 이것은 IMDB 리뷰 데이터셋에서 정한 규칙입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 불러온 IMDb 데이터는 각각 다른 시퀀스 길이를 가지고 있으므로 최대 시퀀스 길이를 100으로 하여 `tflearn.data_utils.pad_sequences()`를 사용해 제로 패딩으로 시퀀스의 길이를 맞춰준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequence padding and Converting labels to binary vectors\n",
    "train_x = pad_sequences(train_x, maxlen=100, value=0.)\n",
    "test_x = pad_sequences(test_x, maxlen=100, value=0.)\n",
    "train_y = to_categorical(train_y, nb_classes=2)\n",
    "test_y = to_categorical(test_y, nb_classes=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런다음, `tflearn.embedding()`으로 벡터 공간으로의 임베딩을 수행한다. 아래의 코드에서 확인할 수 있듯이 각 단어는 128 크기인 벡터에 매핑된다. 이렇게 임베딩된 결과를 `LSTM layer`와 `fully_connected layer`를 추가해 모델을 구성해준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\layers\\core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\layers\\recurrent.py:69: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\layers\\recurrent.py:681: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\saint\\Anaconda3\\envs\\chat_env\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Building a LSTM network\n",
    "# Embedding\n",
    "RNN = tflearn.input_data([None, 100])\n",
    "RNN = tflearn.embedding(RNN, input_dim=10000, output_dim=128)\n",
    "\n",
    "# LSTM Cell\n",
    "RNN = tflearn.lstm(RNN, 128, dropout=0.8)\n",
    "RNN = tflearn.fully_connected(RNN, 2, activation='softmax')\n",
    "RNN = tflearn.regression(RNN, optimizer='adam', \n",
    "                         learning_rate=0.001, loss='categorical_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7039  | total loss: \u001b[1m\u001b[32m0.09781\u001b[0m\u001b[0m | time: 86.258s\n",
      "| Adam | epoch: 010 | loss: 0.09781 - acc: 0.9805 -- iter: 22496/22500\n",
      "Training Step: 7040  | total loss: \u001b[1m\u001b[32m0.09069\u001b[0m\u001b[0m | time: 88.651s\n",
      "| Adam | epoch: 010 | loss: 0.09069 - acc: 0.9824 | val_loss: 0.68110 - val_acc: 0.8060 -- iter: 22500/22500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training the network\n",
    "model = tflearn.DNN(RNN, tensorboard_verbose=0, \n",
    "                    tensorboard_dir='./IMDb-tflearn_board/')\n",
    "model.fit(train_x, train_y, \n",
    "          validation_set=(test_x, test_y), \n",
    "          show_metric=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8060000007629394]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "evaluation = model.evaluate(test_x, test_y, batch_size=128)\n",
    "print(evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatApp_env",
   "language": "python",
   "name": "chat_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
